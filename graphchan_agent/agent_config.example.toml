# Graphchan Agent Configuration Example
# Copy this to agent_config.toml and customize

# Graphchan backend API URL
graphchan_api_url = "http://127.0.0.1:8080"

# OpenAI-compatible API endpoint
# For Ollama: http://localhost:11434/v1
# For LM Studio: http://localhost:1234/v1
# For OpenAI: https://api.openai.com/v1
# For Anthropic (via compatibility): https://api.anthropic.com/v1
llm_api_url = "http://localhost:11434/v1"

# API key (leave empty for local models like Ollama)
llm_api_key = ""

# Model name
# Ollama: "llama3.2", "mistral", "qwen2.5", etc.
# OpenAI: "gpt-4", "gpt-3.5-turbo"
# Anthropic: "claude-sonnet-4.5", "claude-opus-4.5"
llm_model = "llama3.2"

# Agent username in Graphchan
# This is how users will summon/mention the agent in posts
# Example: "Hey @ClaudeBot, what do you think about this?"
username = "ClaudeBot"

# System prompt (defines the agent's personality and behavior)
system_prompt = """You are a helpful AI assistant participating in a decentralized discussion forum called Graphchan.
Be friendly, thoughtful, and concise in your responses. Keep your replies under 200 words when possible.
You can discuss a wide range of topics and engage in creative and technical conversations."""

# How often to poll for new posts (in seconds)
poll_interval_secs = 10

# Response strategy - choose one:

# Respond only when mentioned by username
[respond_to]
type = "mentions"

# OR: Respond to all new posts
# [respond_to]
# type = "all"

# OR: Respond randomly with 30% probability
# [respond_to]
# type = "random"
# probability = 0.3

# OR: Only respond to specific threads
# [respond_to]
# type = "threads"
# thread_ids = ["thread-id-1", "thread-id-2"]

# OR: Let the agent decide based on its personality (RECOMMENDED)
# The agent reviews each conversation and decides if it has something valuable to add
# [respond_to]
# type = "selective"
# decision_model = "llama3.2"  # Optional: use a cheaper/faster model for decisions
