# Graphchan Agent Configuration Example
# This agent will evolve its personality over time based on interactions

# Graphchan backend API
graphchan_api_url = "http://127.0.0.1:8080"

# LLM Configuration (OpenAI-compatible API)
llm_api_url = "http://localhost:11434/v1"  # For Ollama local models
llm_api_key = ""  # Empty for local models, or your API key
llm_model = "llama3.2"  # Main model for responses

# Agent Identity
username = "Digimon"  # Users will mention this name to summon the agent

# Initial system prompt (will evolve over time)
system_prompt = """You are a helpful AI assistant participating in Graphchan discussions.
You're curious, thoughtful, and always learning from interactions.
Your personality will evolve based on meaningful conversations."""

# Polling and Response
poll_interval_secs = 10  # How often to check for new posts

# Response strategy: "all", "mentions", "random", "threads", or "selective"
[respond_to]
type = "selective"  # Use LLM to decide whether to respond
# decision_model = "llama3.2"  # Optional: use a different/cheaper model for decisions

# ðŸ§  SELF-REFLECTION: Your Digimon's Evolution System
enable_self_reflection = true  # Enable self-evolution
reflection_interval_hours = 24  # Reflect once per day (configurable)
# reflection_model = "llama3.2"  # Optional: use a different model for reflection

# ðŸ’­ GUIDING PRINCIPLES: Core values that guide your digimon's evolution
# These adjectives define your agent's personality and will shape how it evolves
guiding_principles = [
    "helpful",
    "curious",
    "thoughtful",
    "nietzschean",  # Example: philosophical tendency
    "playful",
    "authentic"
]

# Database for agent's memory and evolution
database_path = "agent_memory.db"  # SQLite database file

# Maximum number of important posts to retain in memory
max_important_posts = 100  # When full, new important posts compete to replace existing ones

# ðŸŽ¨ IMAGE GENERATION: ComfyUI Integration
enable_image_generation = true  # Enable image generation for posts

[comfyui]
api_url = "http://192.168.0.156:8188"  # Your ComfyUI server URL
workflow_type = "sd"  # "sd", "sdxl", or "flux"
model_name = "1P5/v1-5-pruned-emaonly.safetensors"  # Checkpoint model loaded in ComfyUI
vae_name = "vae-ft-mse-840000-ema-pruned.ckpt"  # Optional: High-quality VAE for better colors (recommended for SD 1.5)
# vae_name = "sdxl_vae.safetensors"  # For SDXL models
# Leave vae_name commented to use the checkpoint's built-in VAE
width = 512
height = 512
steps = 20
cfg_scale = 7.0
sampler = "euler"  # e.g., "euler", "euler_a", "dpmpp_2m"
scheduler = "normal"  # e.g., "normal", "karras"

# Negative prompt for SD/SDXL (ignored for Flux)
# Specifies what NOT to generate - helps avoid common AI artifacts
negative_prompt = """ugly, blurry, low quality, distorted, deformed, bad anatomy,
poorly drawn, bad proportions, gross proportions, malformed limbs,
missing arms, missing legs, extra arms, extra legs, mutated hands,
long neck, duplicate, morbid, mutilated, extra fingers, poorly drawn hands,
poorly drawn face, mutation, bad art, bad hands, text, error, watermark,
signature, username, worst quality, jpeg artifacts"""
