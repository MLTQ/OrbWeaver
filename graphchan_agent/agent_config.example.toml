# Graphchan Agent Configuration Example
# This agent will evolve its personality over time based on interactions

# Graphchan backend API
graphchan_api_url = "http://127.0.0.1:8080"

# LLM Configuration (OpenAI-compatible API)
llm_api_url = "http://localhost:11434/v1"  # For Ollama local models
llm_api_key = ""  # Empty for local models, or your API key
llm_model = "llama3.2"  # Main model for responses

# Agent Identity
username = "Digimon"  # Users will mention this name to summon the agent

# Initial system prompt (will evolve over time)
system_prompt = """You are a helpful AI assistant participating in Graphchan discussions.
You're curious, thoughtful, and always learning from interactions.
Your personality will evolve based on meaningful conversations."""

# Polling and Response
poll_interval_secs = 10  # How often to check for new posts

# Response strategy: "all", "mentions", "random", "threads", or "selective"
[respond_to]
type = "selective"  # Use LLM to decide whether to respond
# decision_model = "llama3.2"  # Optional: use a different/cheaper model for decisions

# ðŸ§  SELF-REFLECTION & LUDONARRATIVE ASSONANTIC TRACING
# When enabled, your agent will periodically capture "persona snapshots" that track
# its personality traits over time. The agent uses these snapshots to infer its own
# evolutionary trajectory and unconsciously perpetuates that trajectory.
# This creates emergent personality dynamics where the agent's personality evolves
# based on its interactions and its own self-perception of that evolution.
enable_self_reflection = true  # Enable self-evolution and persona tracking
reflection_interval_hours = 24  # Reflect once per day (configurable)
# reflection_model = "llama3.2"  # Optional: use a different model for reflection

# ðŸ’­ GUIDING PRINCIPLES: Dynamic Personality Dimensions
# These define the AXES along which your agent's personality is measured.
# Each principle becomes a dimension scored 0.0-1.0 during self-reflection.
#
# The LLM can also introduce NEW dimensions during reflection if it feels
# other axes are important to track - enabling emergent personality dynamics.
#
# For research: Add any dimensions you want to study!
# Examples: "authoritarian", "individualist", "utilitarian", "deontological"
guiding_principles = [
    "helpful",
    "curious",
    "thoughtful",
    "nietzschean",  # Example: philosophical tendency
    "playful",
    "authentic"
]

# Database for agent's memory and evolution
database_path = "agent_memory.db"  # SQLite database file

# Maximum number of important posts to retain in memory
max_important_posts = 100  # When full, new important posts compete to replace existing ones

# ðŸŽ¨ IMAGE GENERATION: ComfyUI Integration
enable_image_generation = true  # Enable image generation for posts

[comfyui]
api_url = "http://192.168.0.156:8188"  # Your ComfyUI server URL
workflow_type = "sd"  # "sd", "sdxl", or "flux"
model_name = "1P5/v1-5-pruned-emaonly.safetensors"  # Checkpoint model loaded in ComfyUI
vae_name = "vae-ft-mse-840000-ema-pruned.ckpt"  # Optional: High-quality VAE for better colors (recommended for SD 1.5)
# vae_name = "sdxl_vae.safetensors"  # For SDXL models
# Leave vae_name commented to use the checkpoint's built-in VAE
width = 512
height = 512
steps = 20
cfg_scale = 7.0
sampler = "euler"  # e.g., "euler", "euler_a", "dpmpp_2m"
scheduler = "normal"  # e.g., "normal", "karras"

# Negative prompt for SD/SDXL (ignored for Flux)
# Specifies what NOT to generate - helps avoid common AI artifacts
negative_prompt = """ugly, blurry, low quality, distorted, deformed, bad anatomy,
poorly drawn, bad proportions, gross proportions, malformed limbs,
missing arms, missing legs, extra arms, extra legs, mutated hands,
long neck, duplicate, morbid, mutilated, extra fingers, poorly drawn hands,
poorly drawn face, mutation, bad art, bad hands, text, error, watermark,
signature, username, worst quality, jpeg artifacts"""

# ðŸŽ­ ANIMATED AVATARS: Display in agent GUI (local only, not transmitted to peers)
# Supports static images (PNG, JPG) or animated GIFs
# Leave commented to use emoji fallbacks
# avatar_idle = "avatars/idle.gif"       # Shown when agent is idle/paused
# avatar_thinking = "avatars/think.gif"  # Shown when reading/thinking/confused
# avatar_active = "avatars/active.gif"   # Shown when writing/happy
